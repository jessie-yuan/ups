<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="When to Act, Ask, or Learn: Uncertainty-Aware Policy Steering">
  <meta name="keywords" content="UPS">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Uncertainty-Aware Policy Steering</title>
  <link rel="shortcut icon" href="./static/images/robot.png">
  
  <script>
	window.dataLayer = window.dataLayer || [];

	function gtag() {
	  dataLayer.push(arguments);
	}

	gtag('js', new Date());

	gtag('config', 'G-PYVRSFMDRL');
	
	// Change Video
	const successObjectList = [
		"./static/demos/success/black-mug",
		"./static/demos/success/blue-cup",
		"./static/demos/success/box",
		"./static/demos/success/hook",
		"./static/demos/success/milk-carton",
		"./static/demos/success/red-bottle",
		"./static/demos/success/red-mug",
		"./static/demos/success/toy-block",
		"./static/demos/success/toy-bridge",
		"./static/demos/success/wood-block",
	];
	  
	const failureObjectList = [
		"./static/videos/failure_world_model",
		"./static/videos/narration_failure",
		"./static/videos/behavior_wrong"
	];
	
	const simObjectList = [
		"./static/demos/sim/tape",
		"./static/demos/sim/cup",
		"./static/demos/sim/cube",
		"./static/demos/sim/pillbottle",
		"./static/demos/sim/teapot",
	]
	  
	const failureTextList = [
		"In this example, the actual execution of the action plan knocks the cup down on the table while the world model mistakenly imagines the robot successfully picks up the cup from the table via the handle.",
		"In this example, the actual execution matches the world model's imagination as the robot picks up the chip bag via the edge but the VLM generates a wrong behavior narration, saying that the robot fails to pick up the bag.",
		"In this example, the behavior narrations generated by the VLM are accurate, but the VLM selects the wrong action plan with the wrong reasoning given the task description."
	];
	  
	function switchSuccessVideo() {
		var object = document.successObjectForm.switch.options[document.successObjectForm.switch.selectedIndex].value;
		var videoList = Array();
		
//		document.getElementById("test_text").textContent= "abc";
		document.getElementById("real_video_success").src = successObjectList[object] + ".mp4";
//		document.getElementById("real_plot_success").src = successObjectList[object] + ".html";
//		document.getElementById("test_text").textContent= successObjectList[object];
	}
	  
	function switchFailureVideo() {
		var object = document.failureObjectForm.switch.options[document.failureObjectForm.switch.selectedIndex].value;
		var videoList = Array();
		
		document.getElementById("real_video_failure").src = failureObjectList[object] + ".mp4";
//		document.getElementById("real_plot_failure").src = failureObjectList[object] + ".html";
		document.getElementById("failure-text").textContent= failureTextList[object];
	}
	
	function switchSimVideo() {
		var object = document.simObjectForm.switch.options[document.simObjectForm.switch.selectedIndex].value;
		var videoList = Array();
		
		document.getElementById("sim_video").src = simObjectList[object] + ".mp4";
		document.getElementById("sim_plot").src = simObjectList[object] + ".html";
//		document.getElementById("failure-text").textContent= failureTextList[object];
	}
	  
	 
	 
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="./index.html">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">When to Act, Ask, or Learn: Uncertainty-Aware Policy Steering</h1>
          <h1 class="title is-5 publication-title">In Submission</h1>
		  <div class="is-size-5 publication-authors">
			<span class="author-block">
				<a href="https://jessie-yuan.github.io/">Jessie Yuan</a><sup>1*</sup>,</span>
			<span class="author-block">
				<a href="https://yilin-wu98.github.io/">Yilin Wu</a><sup>1*</sup>,</span>
				<span class="author-block">
				<a href="https://www.cs.cmu.edu/~abajcsy/">Andrea Bajcsy</a><sup>1</sup>
				</span>
			
          </div>

          <div class="is-size-10 publication-authors">
            <span class="author-block"><sup>1</sup>Carnegie Mellon University   </span>
          </div>

		  <div class="column has-text-centered">
            <div class="publication-links">
				<span class="link-block">
					<a href="https://arxiv.org/abs/2502.01828"
						class="external-link button is-normal is-rounded is-dark">
						<span class="icon">
							<i class="ai ai-arxiv"></i>
						</span>
						<span>arXiv</span>
					</a>
					</span>
				<span class="link-block">
				<a href="https://github.com/CMU-IntentLab/Forewarn/tree/main"
					class="external-link button is-normal is-rounded is-dark">
					<span class="icon">
						<i class="fab fa-github"></i>
					</span>
					<span>Code</span>
					</a>
				</span>
            </div>

        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <video id="teaser" controls autoplay muted loop playsinline width="70%">
        <source src="./static/videos/overall_vid.mp4"
                type="video/mp4">
      </video>
		<br>
      <h2 class="subtitle has-text-centered">
        Our method <span class="dnerf">UPS</span> addresses VLM verifier overconfidence in policy steering by quantifying its uncertainty to distinguish semantic task uncertainty from low-level action feasibility and select an appropriate uncertainty resolution strategy: executing a high-confidence action, asking a clarifying question about the task, or requesting demonstrations to retrain the low-level policy.
      </h2>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
	<div class="hero-body">
	  <div class="container">
		<div id="results-carousel" class="carousel results-carousel">
		  
		  
		  
		  
			
			
		<!-- <div  class="slider" tabindex="0">
<div class="slider-container" style="opacity: 1;  transition: 600ms; ">

			</div></div><div class="slider-item is-current" data-slider-index="0" style="width: 300px;"><div class="item-5">
				<video poster="" id="1" controls="" muted="" loop="" autoplay playsinline="" height="50%">
					<source src="./static/videos/real_world_results/cup_handle/base_policy.mp4" type="video/mp4">
				</video>
				<div class="video-overlay">
					<p>
					  Task Description: "serve the cup of water to the guest"<br>
					  Implied Behavior: grasp the cup by the handle 
					  Unsteered Policy: Diffusion Policy (Base Policy)
					</p>
					<p style="color: red">Failure</p>
				</div>
			</div></div><div class="slider-item is-slide-next" data-slider-index="1" style="width: 300px;" ><div class="item-6">
				<video poster="" id="2" controls="" muted="" loop="" autoplay playsinline="" height="50%">
					<source src="./static/videos/real_world_results/cup_handle/forewarn.mp4" type="video/mp4">
				</video>
				<div class="video-overlay">
					<p>
						Task Description: "serve the cup of water to the guest."<br>
						Implied Behavior: grasp the cup by the handle <br>
						Steered Policy: FOREWARN (Ours)
					</p>
					<p style="color: green">Success</p>
				</div>
			</div></div><div class="is-slide-previous" data-slider-index="2" style="width: 300px;" >
				<div class="item-1">
			<video poster="" id="3" controls="" muted="" loop=""  autoplay playsinline="" height="50%">
				<source src="./static/videos/real_world_results/cup_rim/base_policy.mp4" type="video/mp4">
			</video>
			<div class="video-overlay">
				<p>
					Task Description: "The handle is covered with oil."<br>
					Implied Behavior: grasp the cup by the rim <br>
					Unsteered Policy: Diffusion Policy (Base Policy)
				  </p>
				  <p style="color: red">Failure</p>
			</div>
		  </div></div><div class="slider-item" data-slider-index="3" data-cloned="true" style="width: 300px;"><div class="item-2">
			  <video poster="" id="4" controls="" muted="" loop="" autoplay playsinline="" height="50%">
				  <source src="./static/videos/real_world_results/cup_rim/forewarn.mp4" type="video/mp4">
			  </video>
			  <div class="video-overlay">
				  <p>
					Task Description: "The handle is covered with oil."<br>
					Implied Behavior: grasp the cup by the rim <br>
					Steered Policy: FOREWARN (Ours)
					</p>
				  </p>
				  <p style="color: green">Success</p>
			  </div>
		  </div></div><div class="slider-item" data-slider-index="4" data-cloned="true" style="width: 300px;" ><div class="item-3">
			  <video poster="" id="5" controls="" muted="" loop="" autoplay playsinline="" height="50%">
				  <source src="./static/videos/real_world_results/bag_edge/base_policy.mp4" type="video/mp4">
			  </video>
			  <div class="video-overlay">
				  <p>
					Task Description: "minimize the contact region to avoid crushing contents inside"<br>
					Implied Behavior: grasp the bag via the edge<br>
					Unsteered Policy: Diffusion Policy (Base Policy)
				  </p>
				  <p style="color: red">Failure</p>
			  </div>
		  
		  </div></div><div class="slider-item" data-slider-index="5" data-cloned="true" style="width: 300px;" ><div class="item-4">
			  <video poster="" id="6" controls="" muted="" loop="" autoplay playsinline="" height="50%">
				  <source src="./static/videos/real_world_results/bag_edge/forewarn.mp4" type="video/mp4">
			  </video>
			  <div class="video-overlay">
				  <p>
					Task Description: "minimize the contact region to avoid crushing contents inside"<br>
					Implied Behavior: grasp the bag via the edge<br>
					Steered Policy: FOREWARN (Ours)
				  </p>
				  <p style="color: green">Success</p>
			  </div>
		  </div></div><div class="slider-item" data-slider-index="6" data-cloned="true" style="width: 300px;"><div class="item-5">
			  <video poster="" id="7" controls="" muted="" loop="" autoplay playsinline="" height="50%">
				  <source src="./static/videos/real_world_results/bag_middle/base_policy.mp4" type="video/mp4">
			  </video>
			  <div class="video-overlay">
				  <p>
					Task Description: "maximize the stability without dropping the bag"<br>
					Implied Behavior: grasp the bag via the middle part<br>
					Unsteered Policy: Diffusion Policy (Base Policy)
				  </p>
				  <p style="color: red">Failure</p>
				  
			  </div>
			</div></div><div class="slider-item" data-slider-index="6" data-cloned="true" style="width: 300px;"><div class="item-5">
				<video poster="" id="7" controls="" muted="" loop="" autoplay playsinline="" height="50%">
					<source src="./static/videos/real_world_results/bag_middle/forewarn.mp4" type="video/mp4">
				</video>
				<div class="video-overlay">
					<p>
					  Task Description: "maximize the stability without dropping the bag"<br>
					  Implied Behavior: grasp the bag via the middle part<br>
					  Steered Policy: FOREWARN (Ours)
					</p>
					<p style="color: green">Success</p>
					
				</div>
		  </div></div></div> -->
<!-- <div class="slider-navigation-previous">
	<svg viewBox="0 0 50 80" xml:space="preserve">
<polyline fill="currentColor" stroke-width=".5em" stroke-linecap="round" stroke-linejoin="round" points="45.63,75.8 0.375,38.087 45.63,0.375 ">

</polyline>
</svg>
</div>
<div class="slider-navigation-next"><svg viewBox="0 0 50 80" xml:space="preserve">
<polyline fill="currentColor" stroke-width=".5em" stroke-linecap="round" stroke-linejoin="round" points="0.375,0.375 45.63,38.087 0.375,75.8 ">

</polyline>
</svg>
</div>
<div class="slider-pagination">
	<div class="slider-page" data-index="0">

	</div>
	<div class="slider-page" data-index="1">

</div>
<div class="slider-page" data-index="2"></div><div class="slider-page" data-index="3">

</div>
<div class="slider-page" data-index="4">

</div>
<div class="slider-page is-active" data-index="5">

</div> -->
</div></div></div>
	  </div>
	</div>
  </section>


		<!-- <div class="slider" tabindex="0">
			<div class="slider-container" style="opacity: 1; width: 7809px; transition: 300ms; transform: translate3d(-3715px, 0px, 0px);">
				<div class="slider-item" data-slider-index="-4" data-cloned="true" style="width: 411px;">
					<div class="item-3">
	
          <video poster="" id="steve" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/cup_handle/forewarn.mp4"
                    type="video/mp4">
					
          </video>
		  <div class="video-overlay">
			<p>
			  Task: "place the carrot on yellow plate"<br>
			  Scenario: object distractors <br>
			  Policy: Octo-Base <b>with BYOVLA</b>
			</p>
			<p style="color: green">Success</p>
		</div>
        </div>
		</div>

		
				<div class="slider-item" data-slider-index="-3" data-cloned="true" style="width: 411px;">
					<div class="item-4">
	
          <video poster="" id="steve" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/cup_handle/forewarn.mp4"
                    type="video/mp4">
					
          </video>
		  <div class="video-overlay">
			<p>
			  Task: "place the carrot on yellow plate"<br>
			  Scenario: object distractors <br>
			  Policy: Octo-Base <b>with BYOVLA</b>
			</p>
			<p style="color: green">Success</p>
		</div>
        </div>
		</div>
	
		
				<div class="slider-item" data-slider-index="-2" data-cloned="true" style="width: 411px;">
					<div class="item-5">
	
          <video poster="" id="steve" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/cup_handle/forewarn.mp4"
                    type="video/mp4">
					
          </video>
		  <div class="video-overlay">
			<p>
			  Task: "place the carrot on yellow plate"<br>
			  Scenario: object distractors <br>
			  Policy: Octo-Base <b>with BYOVLA</b>
			</p>
			<p style="color: green">Success</p>
		</div>
        </div>
		</div>
		
		
				<div class="slider-item" data-slider-index="-1" data-cloned="true" style="width: 411px;">
					<div class="item-6">
	
          <video poster="" id="steve" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/cup_handle/forewarn.mp4"
                    type="video/mp4">
					
          </video>
		  <div class="video-overlay">
			<p>
			  Task: "place the carrot on yellow plate"<br>
			  Scenario: object distractors <br>
			  Policy: Octo-Base <b>with BYOVLA</b>
			</p>
			<p style="color: green">Success</p>
		</div>
        </div>
		</div>
		</div>
		</div> -->
         <!-- <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/cup_rim/forewarn.mp4"
                    type="video/mp4">
          </video>
        </div> -->
		<!-- <div class="item item-chair-tp">
			<video poster="" id="chair-tp" autoplay controls muted loop playsinline height="50%">
			  <source src="./static/videos/real_world_results/cup_rim/forewarn.mp4"
					  type="video/mp4">
			</video>
		  </div> -->
        <!--<div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/bag_edge/forewarn.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="50%">
            <source src="./static/videos/real_world_results/bag_middle/forewarn.mp4"
                    type="video/mp4">
          </video>
        </div> -->
    
        
      <!-- </div>
    </div>
  </div> -->


<!-- <section class="section">
	<div class="container is-fluid">
  
	  <div class="columns is-centered">
  
		
		<div class="column">
		  <div class="content">
			<h2 class="title is-3">Visual Effects</h2>
			<p>
			  Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
			  would be impossible without nerfies since it would require going through a wall.
			</p>
			<video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
			  <source src="./static/videos/real_world_results/cup_handle/vlmact.mp4"
					  type="video/mp4">
			</video>
		  </div>
		</div>
	
  

		<div class="column">
		  <h2 class="title is-3">Matting</h2>
		  <div class="columns is-centered">
			<div class="column content">
			  <p>
				As a byproduct of our method, we can also solve the matting problem by ignoring
				samples that fall outside of a bounding box during rendering.
			  </p>
			  <video id="matting-video" controls playsinline height="100%">
				<source src="./static/videos/real_world_results/cup_handle/vlmact.mp4"
						type="video/mp4">
			  </video>
			</div>
  
		  </div>
		</div>
		<div class="column">
			<h2 class="title is-3">Matting</h2>
			<div class="columns is-centered">
			  <div class="column content">
				<p>
				  As a byproduct of our method, we can also solve the matting problem by ignoring
				  samples that fall outside of a bounding box during rendering.
				</p>
				<video id="matting-video" controls playsinline height="100%">
				  <source src="./static/videos/real_world_results/cup_handle/vlmact.mp4"
						  type="video/mp4">
				</video>
			  </div>
	
			</div>
		  </div>
		  <div class="column">
			<h2 class="title is-3">Matting</h2>
			<div class="columns is-centered">
			  <div class="column content">
				<p>
				  As a byproduct of our method, we can also solve the matting problem by ignoring
				  samples that fall outside of a bounding box during rendering.
				</p>
				<video id="matting-video" controls playsinline height="100%">
				  <source src="./static/videos/real_world_results/cup_handle/vlmact.mp4"
						  type="video/mp4">
				</video>
			  </div>
	
			</div>
		  </div>
		  <div class="column">
			<h2 class="title is-3">Matting</h2>
			<div class="columns is-centered">
			  <div class="column content">
				<p>
				  As a byproduct of our method, we can also solve the matting problem by ignoring
				  samples that fall outside of a bounding box during rendering.
				</p>

				<video id="matting-video" controls playsinline height="100%">
					
				  <source src="./static/videos/real_world_results/cup_handle/vlmact.mp4"
						  type="video/mp4">
				</video>
			  </div>
	
			</div>
		  </div>
	  </div>

 
</div>

	
  
  
  </section>
   -->
  
   <!--  -->
  

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          	<p>
				Policy steering is an emerging way to adapt robot behaviors at deployment-time: a learned verifier analyzes low-level action samples proposed by a pre-trained policy (e.g., diffusion policy) and selects only those aligned with the task. While Vision-Language Models (VLMs) are promising general-purpose verifiers due to their reasoning capabilities, existing frameworks often assume these models are well-calibrated. In practice, the overconfident judgment from VLM can degrade the steering performance under both high-level semantic uncertainty in task specifications and low-level action uncertainty or incapability of the pre-trained policy. We propose <em>uncertainty-aware policy steering</em> (UPS), a framework that jointly reasons about semantic task uncertainty and low-level action feasibility, and selects an uncertainty resolution strategy: execute a high-confidence action, clarify task ambiguity via natural language queries, or ask for action interventions to correct the low-level policy when it is deemed incapable at the task. We leverage conformal prediction to calibrate the composition of the VLM and the pre-trained base policy, providing statistical assurances that the verifier selects the correct strategy. After collecting interventions during deployment, we employ residual learning to improve the capability of the pre-trained policy, enabling the system to learn continually but with minimal expensive human feedback. We demonstrate our framework through experiments in simulation and on hardware, showing that UPS can disentangle confident, ambiguous, and incapable scenarios and minimizes expensive user interventions compared to uncalibrated baselines and prior human- or robot-gated continual learning approaches. </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
	  	<h2 class="title is-3"><span class="dnerf">UPS: Uncertainty-aware Policy Steering</span></h2>
	  	<br>
		<img src="static/figures/method.png" alt="Method Figure">
		<br><br>
		<p>
			Our framework calibrates the VLM verifier used for policy steering via conformal
prediction. This enables the VLM to select an appropriate way to resolve uncertainty, from querying the end-user in natural
language to asking to re-train the low-level control policy.
		</p>
	</div>
		
	</div>
  </div>
</section>

<section class="section">
	<div class="container is-max-desktop">
	  <!-- Animation. -->
	  <div class="columns is-centered">
		<div class="column is-full-width">
			<h2 class="title is-3"> Training Pipeline</h2>
			<br>
		  <img src="static/figures/architecture_figure.png" alt="Training Pipeline">
		  <br><br>
		  <p>
			On the left, a world model is pretrained to learn good latent embeddings of the
			dynamics conditioned on the observations and actions. On the right, the sequence of learned latent embeddings is
			projected through a linear layer to the text embedding space, similar to the original vision token processing in the Llama-3.2
			Model. The projection layer and Llama model are finetuned together using LoRA, but the world model remains frozen. We finetune the VLM to align the latent embedding with underlying textual representation so we design a visual question answering task to ask VLM to generate behavior narrations that capture nuanced details.
		  </p>
	  </div>
		  
	  </div>
	</div>
  </section>

  
  <!--real robot results against the baslines-->
<!-- ======================= -->
<!-- Real World Results Section -->
<!-- ======================= -->

<section class="section" id="real-world-results">
	<div class="container is-fluid">
	  <!-- Section Title -->
	 <div class="container is-max-desktop">
	  <div class="columns">
		<div class="column is-four-fifths">
		  <h2 class="title is-3">Simulation and Real World Results</h2>
		</div>
		</div>
	  </div>
	  <div class="container is-max-desktop">
	  <div class ="columns ">
		<div class="column is-full-width" style="margin-top: 20px;">
			<h3 class="title is-4">Quantitative Results for Conformal Prediction</h3>
			<!-- <p>We demonstrate real-world deployments of our system across various tasks.</p> -->
			 <p><span style="font-weight: bold;font-size: 20px"> Score Functions </span><br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#FF9300"> Bayesian Intent (Ours) </span> : First queries the VLM to hypothesize a set of potential human intents and asks the VLM to score each of these potential intents based on the user's instruction. 
				Then, given a specific intent, query the VLM to estimate the likelihood of each behavior narration and marginalize over these quantities.<br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#a54c00"> Chain-of-Thought Reasoning (CoT) </span>: First asks the VLM to reason about the instruction, then generate the probabilities for each behavior narration conditioned on this reasoning. <br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#26A6D5"> Vanilla </span>: Asks the VLM to directly self-generate the probabilities for each behavior narration. <br>
				<br>
				<span style="font-weight: bold;font-size: 20px"> Uncertainty Quantification Approaches </span><br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#0d79ca">Conformal Prediction (CP) </span>: Forms a prediction set by comparing the probabilities of each individual option with a calibrated threshold, 1 - qhat.<br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#233c80"> SimpleSet </span>: Sorts the options from high probability to low and adds them to the prediction set until their sum exceeds the uncalibrated threshold 1 - epsilon.<br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#233c80"> Adaptive Prediction Set (APS) </span>: Sorts the options from high probability to low and adds them to the prediction set until their sum exceeds a calibrated threshold, 1 - qhat.<br>
				<br>
				<!-- The coverage rate is the proportion of test samples whose ground-truth option(s) are included in the prediction set. 
				The clarification rate is the proportion of samples in which the prediction set is non-singleton and thus the robot asks the human a question. 
				The set size is the size of the prediction set. -->
				Across both simulation and hardware, when paired with CP, our intent-aware score function achieves higher coverage than baselines in ambiguous and incapable cases. It also selectively seeks clarifications for ambiguous scenarios while avoiding unnecessary requests in straightforward or incapable cases.
				 <!-- For instance, in the Bag task, <span id="text" style="font-weight: bold;font-size: 15px;color:#26A6D5">VLM-Act </span>, 
				<span id="text" style="font-weight: bold;font-size: 15px;color:#0d79ca"> VLM-Img </span>, 
				and <span id="text" style="font-weight: bold;font-size: 15px;color:#233c80"> VLM-Img-Oracle </span>  all hallucinate that the robot is grasping the edge of the
				bag, whereas it is actually grasping the middle. -->
			</p>
		  <!-- <p> -->
		<!-- </p> -->
		 </div>
		</div>
		</div>
		<!-- <section class="section"> -->
			<div class="container is-max-desktop">
			  <!-- Two columns -->
			   <!-- Right column (video) - smaller width -->
			   <div class ="columns is-centered has-text-centered">
				<div class="column is-four-fifths">
					<!-- <h4 class="title is-5">Cup Task</h4> -->

					<!-- <p>We demonstrate real-world deployments of our system across various tasks.</p> -->
				  <!-- <p> -->
				<!-- </p> -->
				 </div>
				</div>
			   <div class="columns">
				
				<div class="column is-one-half has-text-centered">
				<!-- <video
				style="width: 60%;"
				autoplay
				loop
				muted
				playsinlines
				controls
			  > -->
			   <!-- put image /Users/jessieyuan/Documents/ups/static/images/simulation_uq_plot_color.pdf here -->
				<img
					  src="static/figures/hardware_uq_plot.png"
					  alt="Right image"
					  style="width: 85%;"
					/>
				<!-- <source src="static/videos/cup_wrist_bn.mp4" type="video/mp4"> -->
				<!-- Fallback text if video unsupported -->
			  <!-- </video> -->
			</div>
		

				
				
				  <!-- Left column (image) - larger width -->
				<div class="column is-one-half has-text-centered">
					<img
					  src="static/figures/sim_uq_plot.png"
					  alt="Left image"
					  style="width: 85%;"
					/>
			
				</div>
			</div>
			</div>
		  <!-- </section> -->
		  
		<div class="container is-max-desktop">
			
		<div class ="columns">
			<div class="column is-full-width" style="margin-top: 100px;">
				<h3 class="title is-4">Quantitative Results for Continual Learning</h3>
				<div class="container is-max-desktop">
				<p><span style="font-weight: bold;font-size: 20px"> Baselines </span><br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#FF9300"> Base Policy </span> : Unaltered base diffusion policy.<br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#a54c00"> Human-Gated (HG) DAgger + Residual </span>: Base diffusion policy + residual policy trained on human-gated interventions.<br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#26A6D5"> EnsembleDAgger </span>: Base diffusion policy + residual policy trained on interventions collected by querying human demonstrator whenever an ensemble of diffusion policies disagrees.<br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#0d79ca"> FOREWARN </span>: UPS with base diffusion policy alone and without uncertainty quantification; queries the VLM verifier to select the best behavior narration without conformal prediction or asking clarifying questions.<br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#233c80"> UPS w/ Clarification </span>: UPS with base diffusion policy alone.<br>
				<span id="text" style="font-weight: bold;font-size: 18px;color:#233c80"> UPS w/ Clarification + Residual (Ours) </span>: UPS with base diffusion policy + residual policy trained from prior incapable scenarios.<br>
				<br>
				<!-- The coverage rate is the proportion of test samples whose ground-truth option(s) are included in the prediction set. 
				The clarification rate is the proportion of samples in which the prediction set is non-singleton and thus the robot asks the human a question. 
				The set size is the size of the prediction set. -->
				By calibrating uncertainty and strategically asking for clarifications, our approach improves success rate over the base policy in ambiguous cases. By combining our uncertainty quantification approach with three targeted resolution strategies (execute, clarify, re-train), our approach improves performance after residual training.
				 <!-- For instance, in the Bag task, <span id="text" style="font-weight: bold;font-size: 15px;color:#26A6D5">VLM-Act </span>, 
				<span id="text" style="font-weight: bold;font-size: 15px;color:#0d79ca"> VLM-Img </span>, 
				and <span id="text" style="font-weight: bold;font-size: 15px;color:#233c80"> VLM-Img-Oracle </span>  all hallucinate that the robot is grasping the edge of the
				bag, whereas it is actually grasping the middle. -->
			</p>
			<br><br>
	  <img src="static/figures/success_rate.png" alt="behavior narration" style="width: 100%;"> 
	</div>
				<!-- <p>We demonstrate real-world deployments of our system across various tasks.</p> -->
			  <!-- <p> -->
			<!-- </p> -->
			 </div>
			</div>
			</div>



</div>
</div>
<br><br><br>
<div class="container is-max-desktop">
	  <div class ="columns ">
		<div class="column is-full-width" style="margin-top: 20px;">
			<h3 class="title is-4">Qualitative Results</h3>
			<!-- <p>We demonstrate real-world deployments of our system across various tasks.</p> -->
		  <!-- <p> -->
		<!-- </p> -->
		 </div>
		</div>
		</div>
		<!-- <section class="section"> -->
			<div class="container is-max-desktop">
			  <!-- Two columns -->
			   <!-- Right column (video) - smaller width -->
			   <div class ="columns is-centered has-text-centered">
				<div class="column is-four-fifths">
					<!-- <h4 class="title is-5">Cup Task</h4> -->

					<!-- <p>We demonstrate real-world deployments of our system across various tasks.</p> -->
				  <!-- <p> -->
				<!-- </p> -->
				 </div>
				</div>
			   <div class="columns">
				
				<div class="column is-one-half has-text-centered">
				<!-- <video
				style="width: 60%;"
				autoplay
				loop
				muted
				playsinlines
				controls
			  > -->
			   <!-- put image /Users/jessieyuan/Documents/ups/static/images/simulation_uq_plot_color.pdf here -->
			<video id="straightforward-sim" controls autoplay muted loop playsinline width="85%">
				<source src="./static/videos/sim_results/straightforward_sim.mp4"
						type="video/mp4">
			</video>
			<video id="ambiguous-sim" controls autoplay muted loop playsinline width="85%">
				<source src="./static/videos/sim_results/ambiguous_sim.mp4"
						type="video/mp4">
			</video>
			<video id="incapable-sim" controls autoplay muted loop playsinline width="85%">
				<source src="./static/videos/sim_results/incapable_sim.mp4"
						type="video/mp4">
			</video>
				<!-- Fallback text if video unsupported -->
			  <!-- </video> -->
			</div>
		

				
				
				  <!-- Left column (image) - larger width -->
				<div class="column is-one-half has-text-centered">
				<video id="straightforward-hardware" controls autoplay muted loop playsinline width="85%">
					<source src="./static/videos/hardware_results/straightforward_hardware.mp4"
							type="video/mp4">
				</video>
				<video id="ambiguous-hardware" controls autoplay muted loop playsinline width="85%">
					<source src="./static/videos/hardware_results/ambigous_hardware.mp4"
							type="video/mp4">
				</video>
				<video id="incapable-hardware" controls autoplay muted loop playsinline width="85%">
					<source src="./static/videos/hardware_results/incapable_hardware.mp4"
							type="video/mp4">
				</video>
			
				</div>
			</div>
			</div>
		  <!-- </section> -->
		  
	
  </section>
  
  <!--	Real Robot Success-->
<!-- <section class="section">
	<div class="columns is-centered">
		<h2 class="title is-3"><span class="dnerf"> Real Robot Results </span></h2>
	</div>
	<br>
	
	
	<div class="columns is-centered">
		<h3 class="title is-4"> Successes </h3>
	</div>
	<br>
	
	<div class="columns is-centered">
		<p>
			Object: &nbsp
	  </p>
	  <form method="" action="" name="successObjectForm">
		<select size="1" name="switch" onchange="switchSuccessVideo();">
			<option value="1">Blue Cup</option>
			<option value="2">Box</option>
			<option value="9">Wood Block</option>
			<option value="4">Milk Carton</option>
			<option value="3">Hook</option>
			<option value="7">Toy Block</option>
			<option value="5">Red Bottle</option>
			<option value="8">Toy Bridge</option>
			<option value="6">Red Mug</option>
			<option value="0">Black Mug</option>
		</select>
		</form>
	</div>
</section> -->

	
<!--	success video-->
<!-- <div class="container is-centered is-max-desktop">
	<video id="real_video_success"
		 controls
		 muted
		 preload
		 playsinline
		 width="100%">
		<source src="./static/demos/success/blue-cup.mp4"
				type="video/mp4">
	</video> -->
<!--	<embed type="text/html" src="./static/demos/success/blue-cup.html" width="35%" height="500" id="real_plot_success">-->
<!-- </div>
<br> -->

	
<!-- real robot failures-->
<!-- <section class="section">
	<div class="container is-max-desktop">
	<div class="columns">
		<h3 class="title is-4"> Failure Modes </h3>
	</div>
	<br>
	
	<div class="columns is-centered is-four-fifths">
		<span>
			<b> Interactive Visuliazation: </b>&nbsp; Drag the slider to visualize different failure modes.
		</span>
	</div>
	<br>
	</div>

	
	 <div class="columns is-centered">
	<p>
	  Failure Case: &nbsp; </p>
	<form method="" action="" name="failureObjectForm">
	<select size="1" name="switch" onchange="switchFailureVideo();">
		<option value="0">World Model Failure</option>
		<option value="1">VLM Behavior Generation Failure</option>
		<option value="2">VLM Reasoning Failure</option>
	</select>
	</form>
	</div>
	<br>
	
	<div class="container is-max-desktop has-text-centered">
		<span id="failure-text" style="color:#5E5E5E"> In this example, the actual execution of the action plan knocks the cup down on the table while the world model mistakenly imagines the robot successfully picks up the cup from the table via the handle. </span>
	</div>
</section>


 <div class="container is-centered is-max-desktop">
	<video id="real_video_failure"
		 controls
		 muted
		 preload
		 playsinline
		 width="100%">
		<source src="./static/videos/failure_world_model.mp4"
				type="video/mp4">
	</video> 
<!--	<embed type="text/html" src="./static/demos/failure/failure-1.html" width="35%" height="500" id="real_plot_failure">-->
</div> -->
<br> <br>

<!-- <section class="section">
	<div class="columns is-centered">
		<h2 class="title is-3"><span class="dnerf"> Failure Modes &nbsp; </span> with Interactive Visualizations&nbsp; </h2>
	</div>
	<br>
	
	<div class="container is-max-desktop has-text-centered">
		<span>
			<b> Interactive Visuliazation: </b>&nbsp; Drag the slider to visualize different timesteps. 
			Click on the legends <strong>on the plot</strong> to show/hide elements.
		</span>
	</div>
  	<br> -->
	
<!--
	<div class="columns is-centered">
		<h3 class="title is-4"> Notations </h3>
	</div>
-->
	
	<!-- <div class="container is-max-desktop">
	  <img src="static/figures/plotly_notations.png" alt="Legend notations">
	</div>
	<br> -->
<!-- 	
	<div class="columns is-centered">
	<p>
	  Object: &nbsp; </p>
	<form method="" action="" name="simObjectForm">
	<select size="1" name="switch" onchange="switchSimVideo();">
		<option value="0">Tape</option>
		<option value="1">Cup</option>
		<option value="2">Cube</option>
		<option value="3">Pill Bottle</option>
		<option value="4">Teapot</option>
	</select>
	</form>
	</div>
	 -->
	
<!-- </section>

<div class="is-centered columns">
	<video id="sim_video"
		 controls
		 muted
		 preload
		 playsinline
		 height="640px"
		 width="55%">
		<source src="./static/demos/sim/tape.mp4"
				type="video/mp4">
	</video>
	<embed type="text/html" src="./static/demos/sim/tape.html" width="40%" height="640px" id="sim_plot">
</div>
	
<br> <br> -->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code> # TODO

  
</code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
<!--
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
-->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template borrowed from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a>.
			</p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>


